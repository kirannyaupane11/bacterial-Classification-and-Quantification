{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirannyaupane11/bacterial-Classification-and-Quantification/blob/main/Bacterial_Classification_and_Quantification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmW8TeFD_nKs",
        "outputId": "44fa1aac-7332-4ad6-d8d2-2c1c65e19928"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyrlYl84A1cM",
        "outputId": "8973685c-29f5-4518-d4df-8f6a647dcea2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset\"\n",
        "import os\n",
        "print(os.path.exists(DATA_ROOT), DATA_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST_Fr7BcPuSV",
        "outputId": "11dddcf1-cfac-4595-a7e8-3cd552a6f161"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True /content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install albumentations opencv-python\n"
      ],
      "metadata": {
        "id": "2FHoJ7zkCCMA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "\n",
        "train_img_dir = f\"/content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset/train/patches/fluorescence\"\n",
        "train_msk_dir = f\"/content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset/train/patches/masks\"\n",
        "\n",
        "imgs = sorted(glob.glob(train_img_dir + \"/*.tif\"))\n",
        "msks = sorted(glob.glob(train_msk_dir + \"/*.tif\"))\n",
        "\n",
        "print(\"Train patches:\", len(imgs), len(msks))\n",
        "\n",
        "# Added a check to prevent IndexError if lists are empty\n",
        "if imgs and msks:\n",
        "    print(\"Example:\", imgs[0], msks[0])\n",
        "else:\n",
        "    print(\"No images or masks found. Check DATA_ROOT path and directory contents.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMzvtOt7CE9n",
        "outputId": "6a6ae292-724d-4d0b-a212-df246dc9f9a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train patches: 28 28\n",
            "Example: /content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset/train/patches/fluorescence/JE2NileRed_oilp22_PMP_101220_001_1.tif /content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset/train/patches/masks/JE2NileRed_oilp22_PMP_101220_001_1.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_imgs, val_imgs, train_msks, val_msks = train_test_split(\n",
        "    imgs, msks, test_size=0.2, random_state=42\n",
        ")\n",
        "print(len(train_imgs), len(val_imgs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYPIfVOmQGu5",
        "outputId": "8f68fbbf-2724-4888-c938-5ba4e238c4ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BacteriaSegDataset(Dataset):\n",
        "    def __init__(self, img_paths, mask_paths, augment=False):\n",
        "        self.img_paths = img_paths\n",
        "        self.mask_paths = mask_paths\n",
        "\n",
        "        if augment:\n",
        "            self.transform = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.VerticalFlip(p=0.5),\n",
        "                A.Rotate(limit=20, p=0.5),\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Explicitly load image and mask as grayscale to ensure consistent channel dimension\n",
        "        img = cv2.imread(self.img_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        msk = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Handle potential None if image reading fails\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Could not read image: {self.img_paths[idx]}\")\n",
        "        if msk is None:\n",
        "            raise FileNotFoundError(f\"Could not read mask: {self.mask_paths[idx]}\")\n",
        "\n",
        "        # ensure float32\n",
        "        img = img.astype(np.float32)\n",
        "        msk = msk.astype(np.float32)\n",
        "\n",
        "        # normalise image to 0..1\n",
        "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "\n",
        "        # binarise mask to 0/1\n",
        "        msk = (msk > 0).astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            aug = self.transform(image=img, mask=msk)\n",
        "            img, msk = aug[\"image\"], aug[\"mask\"]\n",
        "\n",
        "        # add channel dimension: (1,H,W)\n",
        "        # Now img and msk should consistently be (H,W) arrays, so unsqueeze(0) will result in (1,H,W)\n",
        "        img = torch.tensor(img).unsqueeze(0)\n",
        "        msk = torch.tensor(msk).unsqueeze(0)\n",
        "\n",
        "        return img, msk\n"
      ],
      "metadata": {
        "id": "9-uQRyMEQfTW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = BacteriaSegDataset(train_imgs, train_msks, augment=True)\n",
        "val_ds   = BacteriaSegDataset(val_imgs, val_msks, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "a9KrkzRQQo2B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = DoubleConv(1, 32)\n",
        "        self.d2 = DoubleConv(32, 64)\n",
        "        self.d3 = DoubleConv(64, 128)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.b = DoubleConv(128, 256)\n",
        "\n",
        "        self.u3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.c3 = DoubleConv(256, 128)\n",
        "        self.u2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.c2 = DoubleConv(128, 64)\n",
        "        self.u1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
        "        self.c1 = DoubleConv(64, 32)\n",
        "\n",
        "        self.out = nn.Conv2d(32, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.d1(x)\n",
        "        x2 = self.d2(self.pool(x1))\n",
        "        x3 = self.d3(self.pool(x2))\n",
        "        xb = self.b(self.pool(x3))\n",
        "\n",
        "        x = self.u3(xb)\n",
        "        x = self.c3(torch.cat([x, x3], dim=1))\n",
        "        x = self.u2(x)\n",
        "        x = self.c2(torch.cat([x, x2], dim=1))\n",
        "        x = self.u1(x)\n",
        "        x = self.c1(torch.cat([x, x1], dim=1))\n",
        "        return self.out(x)\n"
      ],
      "metadata": {
        "id": "Q2o1hi2RQuAL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coeff(pred, target, eps=1e-7):\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "    inter = (pred * target).sum()\n",
        "    return (2*inter + eps) / (pred.sum() + target.sum() + eps)\n",
        "\n",
        "def iou_coeff(pred, target, eps=1e-7):\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "    inter = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum() - inter\n",
        "    return (inter + eps) / (union + eps)\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def loss_fn(logits, target):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    dice = dice_coeff((probs > 0.5).float(), target)\n",
        "    return bce(logits, target) + (1 - dice)\n"
      ],
      "metadata": {
        "id": "JmxUYtIfQ97w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = UNet().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss, total_dice, total_iou = 0, 0, 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).float()\n",
        "\n",
        "            d = dice_coeff(preds, y).item()\n",
        "            j = iou_coeff(preds, y).item()\n",
        "\n",
        "            if train:\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_dice += d\n",
        "        total_iou  += j\n",
        "\n",
        "    n = len(loader)\n",
        "    return total_loss/n, total_dice/n, total_iou/n\n",
        "\n",
        "best_val = 0\n",
        "for epoch in range(1, 50):\n",
        "    tr = run_epoch(train_loader, train=True)\n",
        "    va = run_epoch(val_loader, train=False)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train loss {tr[0]:.3f} dice {tr[1]:.3f} iou {tr[2]:.3f} | \"\n",
        "          f\"val loss {va[0]:.3f} dice {va[1]:.3f} iou {va[2]:.3f}\")\n",
        "\n",
        "    if va[1] > best_val:\n",
        "        best_val = va[1]\n",
        "        torch.save(model.state_dict(), \"best_unet.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKQsyz1-RL9G",
        "outputId": "d3638d95-6187-4561-f0b8-1a59b22d9518"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train loss 1.514 dice 0.170 iou 0.097 | val loss 1.675 dice 0.045 iou 0.023\n",
            "Epoch 02 | train loss 1.293 dice 0.291 iou 0.176 | val loss 1.657 dice 0.051 iou 0.026\n",
            "Epoch 03 | train loss 1.232 dice 0.286 iou 0.173 | val loss 1.073 dice 0.378 iou 0.251\n",
            "Epoch 04 | train loss 1.137 dice 0.342 iou 0.217 | val loss 1.441 dice 0.060 iou 0.031\n",
            "Epoch 05 | train loss 1.134 dice 0.300 iou 0.185 | val loss 1.450 dice 0.000 iou 0.000\n",
            "Epoch 06 | train loss 1.155 dice 0.250 iou 0.155 | val loss 1.472 dice 0.001 iou 0.001\n",
            "Epoch 07 | train loss 1.187 dice 0.186 iou 0.106 | val loss 1.507 dice 0.015 iou 0.008\n",
            "Epoch 08 | train loss 1.226 dice 0.121 iou 0.065 | val loss 1.519 dice 0.000 iou 0.000\n",
            "Epoch 09 | train loss 1.216 dice 0.114 iou 0.063 | val loss 1.321 dice 0.000 iou 0.000\n",
            "Epoch 10 | train loss 1.277 dice 0.045 iou 0.023 | val loss 1.291 dice 0.048 iou 0.025\n",
            "Epoch 11 | train loss 1.117 dice 0.186 iou 0.106 | val loss 1.178 dice 0.247 iou 0.148\n",
            "Epoch 12 | train loss 1.284 dice 0.006 iou 0.003 | val loss 1.193 dice 0.191 iou 0.109\n",
            "Epoch 13 | train loss 1.157 dice 0.116 iou 0.063 | val loss 1.067 dice 0.195 iou 0.113\n",
            "Epoch 14 | train loss 1.161 dice 0.095 iou 0.051 | val loss 1.249 dice 0.013 iou 0.006\n",
            "Epoch 15 | train loss 1.145 dice 0.104 iou 0.057 | val loss 1.183 dice 0.047 iou 0.024\n",
            "Epoch 16 | train loss 1.133 dice 0.102 iou 0.055 | val loss 1.233 dice 0.016 iou 0.008\n",
            "Epoch 17 | train loss 1.208 dice 0.012 iou 0.006 | val loss 1.213 dice 0.023 iou 0.012\n",
            "Epoch 18 | train loss 1.066 dice 0.144 iou 0.087 | val loss 1.145 dice 0.081 iou 0.043\n",
            "Epoch 19 | train loss 1.096 dice 0.106 iou 0.061 | val loss 1.194 dice 0.019 iou 0.010\n",
            "Epoch 20 | train loss 1.080 dice 0.114 iou 0.068 | val loss 1.081 dice 0.121 iou 0.065\n",
            "Epoch 21 | train loss 1.163 dice 0.022 iou 0.011 | val loss 1.179 dice 0.009 iou 0.005\n",
            "Epoch 22 | train loss 1.054 dice 0.122 iou 0.069 | val loss 1.089 dice 0.084 iou 0.044\n",
            "Epoch 23 | train loss 1.020 dice 0.152 iou 0.087 | val loss 1.061 dice 0.101 iou 0.053\n",
            "Epoch 24 | train loss 1.112 dice 0.055 iou 0.031 | val loss 1.142 dice 0.011 iou 0.005\n",
            "Epoch 25 | train loss 1.053 dice 0.104 iou 0.060 | val loss 1.117 dice 0.033 iou 0.017\n",
            "Epoch 26 | train loss 1.082 dice 0.071 iou 0.037 | val loss 1.126 dice 0.021 iou 0.011\n",
            "Epoch 27 | train loss 1.003 dice 0.143 iou 0.089 | val loss 1.075 dice 0.060 iou 0.031\n",
            "Epoch 28 | train loss 0.988 dice 0.154 iou 0.101 | val loss 1.076 dice 0.053 iou 0.027\n",
            "Epoch 29 | train loss 1.093 dice 0.053 iou 0.031 | val loss 1.097 dice 0.029 iou 0.015\n",
            "Epoch 30 | train loss 1.023 dice 0.112 iou 0.067 | val loss 1.119 dice 0.004 iou 0.002\n",
            "Epoch 31 | train loss 1.034 dice 0.096 iou 0.066 | val loss 1.117 dice 0.004 iou 0.002\n",
            "Epoch 32 | train loss 0.970 dice 0.156 iou 0.117 | val loss 1.098 dice 0.022 iou 0.011\n",
            "Epoch 33 | train loss 1.067 dice 0.062 iou 0.034 | val loss 1.113 dice 0.000 iou 0.000\n",
            "Epoch 34 | train loss 1.099 dice 0.029 iou 0.015 | val loss 1.106 dice 0.003 iou 0.001\n",
            "Epoch 35 | train loss 1.020 dice 0.102 iou 0.062 | val loss 1.010 dice 0.094 iou 0.049\n",
            "Epoch 36 | train loss 1.091 dice 0.026 iou 0.013 | val loss 1.079 dice 0.017 iou 0.008\n",
            "Epoch 37 | train loss 1.112 dice 0.005 iou 0.002 | val loss 1.099 dice 0.001 iou 0.000\n",
            "Epoch 38 | train loss 1.046 dice 0.067 iou 0.036 | val loss 1.095 dice 0.005 iou 0.003\n",
            "Epoch 39 | train loss 1.108 dice 0.019 iou 0.009 | val loss 1.097 dice 0.000 iou 0.000\n",
            "Epoch 40 | train loss 1.073 dice 0.035 iou 0.019 | val loss 1.098 dice 0.000 iou 0.000\n",
            "Epoch 41 | train loss 1.099 dice 0.012 iou 0.006 | val loss 1.092 dice 0.003 iou 0.002\n",
            "Epoch 42 | train loss 1.081 dice 0.024 iou 0.012 | val loss 1.087 dice 0.005 iou 0.003\n",
            "Epoch 43 | train loss 1.052 dice 0.048 iou 0.026 | val loss 1.091 dice 0.000 iou 0.000\n",
            "Epoch 44 | train loss 1.027 dice 0.073 iou 0.047 | val loss 1.077 dice 0.008 iou 0.004\n",
            "Epoch 45 | train loss 0.851 dice 0.248 iou 0.218 | val loss 1.038 dice 0.054 iou 0.028\n",
            "Epoch 46 | train loss 1.014 dice 0.083 iou 0.050 | val loss 1.063 dice 0.023 iou 0.012\n",
            "Epoch 47 | train loss 1.096 dice 0.004 iou 0.002 | val loss 1.078 dice 0.007 iou 0.004\n",
            "Epoch 48 | train loss 1.059 dice 0.038 iou 0.020 | val loss 1.082 dice 0.001 iou 0.001\n",
            "Epoch 49 | train loss 1.005 dice 0.089 iou 0.052 | val loss 1.040 dice 0.048 iou 0.025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_dir = f\"/content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset/test/fluorescence\"\n",
        "test_msk_dir = f\"/content/drive/MyDrive/Staphylocococcus aureus datasets/DeepBacs_Data_Segmentation_Staph_Aureus_dataset/fluorescence_dataset/test/masks\"\n",
        "\n",
        "test_imgs = sorted(glob.glob(test_img_dir + \"/*.tif\"))\n",
        "test_msks = sorted(glob.glob(test_msk_dir + \"/*.tif\"))\n",
        "\n",
        "if not test_imgs or not test_msks:\n",
        "    print(\"Warning: No test images or masks found. Skipping test evaluation.\")\n",
        "else:\n",
        "    test_ds = BacteriaSegDataset(test_imgs, test_msks, augment=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_unet.pth\", map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    test_loss, test_dice, test_iou = run_epoch(test_loader, train=False)\n",
        "    print(\"TEST | loss:\", test_loss, \"dice:\", test_dice, \"iou:\", test_iou)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG7HhS5lSTAg",
        "outputId": "7b32dcff-1d43-4fb7-ac44-bede021c8de3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST | loss: 0.8068059086799622 dice: 0.6257587015628815 iou: 0.46699504256248475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quantify(mask01):\n",
        "    # mask01: numpy array 0/1\n",
        "    coverage = mask01.mean() * 100.0\n",
        "\n",
        "    mask_u8 = (mask01 * 255).astype(np.uint8)\n",
        "    num_labels, labels = cv2.connectedComponents(mask_u8)\n",
        "    # subtract background label 0\n",
        "    count = max(0, num_labels - 1)\n",
        "    return coverage, count\n",
        "\n",
        "for i, (x, y) in enumerate(test_loader):\n",
        "    x = x.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        pred = (torch.sigmoid(logits) > 0.5).float().cpu().numpy()[0,0]\n",
        "\n",
        "    cov, cnt = quantify(pred)\n",
        "    print(f\"Test image {i+1}: coverage={cov:.2f}% | count={cnt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMD0T-s3TKMI",
        "outputId": "fce3faf2-5021-46a3-b622-0f579b1c534a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test image 1: coverage=2.94% | count=31\n",
            "Test image 2: coverage=4.97% | count=33\n",
            "Test image 3: coverage=6.40% | count=62\n",
            "Test image 4: coverage=3.49% | count=58\n",
            "Test image 5: coverage=1.74% | count=34\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}